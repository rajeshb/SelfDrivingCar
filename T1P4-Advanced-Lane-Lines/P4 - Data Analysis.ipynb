{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project - Data Analysis & Exploration\n",
    "\n",
    "The overall goals of the Advanced Lane Line project include:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "In this data analysis/exploration project, we explore data in each of the steps above and make decision towards our final solution for the project.\n",
    "\n",
    "---\n",
    "## 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating camera ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from image_functions import *\n",
    "\n",
    "images = glob.glob(\"./camera_cal/calibration*.jpg\")\n",
    "nx = 9 #enter the number of inside corners in x\n",
    "ny = 6 #enter the number of inside corners in y\n",
    "print(\"Calibrating camera ...\")\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera(images, nx, ny)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# camera calibration - steps\n",
    "img = cv2.imread('./camera_cal/calibration3.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "if ret == True:\n",
    "    corners_img = np.copy(img)\n",
    "    # draw chessboard corners\n",
    "    cv2.drawChessboardCorners(corners_img, (nx, ny), corners, ret)\n",
    "\n",
    "# undist image\n",
    "undist_img = undistort_image(img, mtx, dist)\n",
    "\n",
    "# plot and save image\n",
    "images_to_plot = [img, corners_img, undist_img]\n",
    "titles_to_plot = ['Original', 'Chessboard corners', 'Distortion corrected']\n",
    "out_file = \"calibration.png\"\n",
    "plot_images(rows=1, cols=3, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Undistort Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick a test image\n",
    "img = cv2.imread('./test_images/straight_lines1.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "undist_img = undistort_image(img, mtx, dist)\n",
    "\n",
    "# plot and save image\n",
    "images_to_plot = [img, undist_img]\n",
    "titles_to_plot = ['Original', 'Undistort']\n",
    "out_file = \"undistort.png\"\n",
    "plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unwarp Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_height, img_width = undist_img.shape[:2]\n",
    "\n",
    "'''\n",
    "# source points\n",
    "top_left = (588, 454)\n",
    "top_right = (692, 454)\n",
    "bottom_left = (203, 720)\n",
    "bottom_right = (1105, 720)\n",
    "\n",
    "src = np.float32([top_right,\n",
    "                  bottom_right, \n",
    "                  bottom_left, \n",
    "                  top_left])\n",
    "\n",
    "# desired destination\n",
    "dst_top_left = (200, 0)\n",
    "dst_top_right = (1000, 0)\n",
    "dst_bottom_right = (1000, 720)\n",
    "dst_bottom_left = (200, 720)\n",
    "\n",
    "dst = np.float32([dst_top_right,\n",
    "                  dst_bottom_right, \n",
    "                  dst_bottom_left, \n",
    "                  dst_top_left])\n",
    "'''\n",
    "src, dst = get_src_dst_coordinates()\n",
    "\n",
    "# unwarp\n",
    "unwarp, M, Minv = unwarp_image(undist_img, src, dst)\n",
    "\n",
    "# draw lines for the source points, for plotting\n",
    "undist_img_plot = np.copy(undist_img)\n",
    "cv2.line(undist_img_plot, tuple(src[2]), tuple(src[1]), color=(255,0,0), thickness=5)\n",
    "cv2.line(undist_img_plot, tuple(src[1]), tuple(src[0]), color=(255,0,0), thickness=5)\n",
    "cv2.line(undist_img_plot, tuple(src[0]), tuple(src[3]), color=(255,0,0), thickness=5)\n",
    "cv2.line(undist_img_plot, tuple(src[3]), tuple(src[2]), color=(255,0,0), thickness=5)\n",
    "\n",
    "# unwarp image for plotting\n",
    "unwarp_img_plot, M_plot, Minv_plot = unwarp_image(undist_img_plot, src, dst)\n",
    "\n",
    "# plot and save image\n",
    "images_to_plot = [undist_img_plot, unwarp]\n",
    "titles_to_plot = ['Undistort with src points', \"Unwarped (Bird's eye view)\"]\n",
    "out_file = \"unwarped.png\"\n",
    "plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Color Channels Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Image Comparison (in different color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_image_color_spaces(img_RGB):\n",
    "    # setup image channels\n",
    "    img_R = img_RGB[:,:,0]\n",
    "    img_G = img_RGB[:,:,1]\n",
    "    img_B = img_RGB[:,:,2]\n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HSV)\n",
    "    img_H = img_HSV[:,:,0]\n",
    "    img_S = img_HSV[:,:,1]\n",
    "    img_V = img_HSV[:,:,2]\n",
    "    img_HLS = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HLS)\n",
    "    img_H1 = img_HLS[:,:,0]\n",
    "    img_L1 = img_HLS[:,:,1]\n",
    "    img_S1 = img_HLS[:,:,2]\n",
    "    \n",
    "    # plot and save image\n",
    "    images_to_plot = [img_R, img_G, img_B, img_H, img_S, img_V, img_H1, img_L1, img_S1]\n",
    "    titles_to_plot = ['R','G','B','H','S','V','H','L','S']\n",
    "    cmap_gray=['gray','gray','gray','gray','gray','gray','gray','gray','gray']\n",
    "    out_file = \"color_channels.png\"\n",
    "    plot_images(rows=3, cols=3, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=cmap_gray)\n",
    "    \n",
    "plot_image_color_spaces(undist_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RGB Colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "def select(img, ch, thresh):\n",
    "    channel = img[:,:,ch]\n",
    "    out = np.zeros_like(channel)\n",
    "    out[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    return out\n",
    "\n",
    "def updateRGB(ch, thresh_min, thresh_max):\n",
    "    out_img = select(unwarp, ch, thresh=(thresh_min, thresh_max))\n",
    "    \n",
    "    # plot and save image\n",
    "    images_to_plot = [unwarp, out_img]\n",
    "    titles_to_plot = ['Unwarped', 'RGB image channel:{} range:({}-{})'.format(ch, thresh_min, thresh_max)]\n",
    "    out_file = \"colorspace_RGB_{}.png\".format(ch)\n",
    "    plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,'gray'])\n",
    "\n",
    "interact(updateRGB, \n",
    "         ch=(0,2),\n",
    "         thresh_min=(0,255),\n",
    "         thresh_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 HSV Colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(unwarp, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def updateHSV(ch, thresh_min, thresh_max):\n",
    "    out_img = select(hsv, ch, thresh=(thresh_min, thresh_max))\n",
    "\n",
    "    # plot and save image\n",
    "    images_to_plot = [unwarp, out_img]\n",
    "    titles_to_plot = ['Unwarped', 'HSV image channel:{} range:({}-{})'.format(ch, thresh_min, thresh_max)]\n",
    "    out_file = \"colorspace_HSV_{}.png\".format(ch)\n",
    "    plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,'gray'])\n",
    "\n",
    "interact(updateHSV, \n",
    "         ch=(0,2),\n",
    "         thresh_min=(0,255),\n",
    "         thresh_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 HLS Colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hls = cv2.cvtColor(unwarp, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "def updateHLS(ch, thresh_min, thresh_max):\n",
    "    out_img = select(hls, ch, thresh=(thresh_min, thresh_max))\n",
    "\n",
    "    # plot and save image\n",
    "    images_to_plot = [unwarp, out_img]\n",
    "    titles_to_plot = ['Unwarped', 'HLS image channel:{} range:({}-{})'.format(ch, thresh_min, thresh_max)]\n",
    "    out_file = \"colorspace_HLS_{}.png\".format(ch)\n",
    "    plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,'gray'])\n",
    "\n",
    "interact(updateHLS, \n",
    "         ch=(0,2),\n",
    "         thresh_min=(0,255),\n",
    "         thresh_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Yellow color lane mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_filename_list = ['./test_images/straight_lines1.jpg', './test_images/test5.jpg', './test_images/org_134.jpg', './test_images/org_195.jpg', './test_images/test4.jpg','./test_images/test6.jpg','./test_images/test1.jpg']\n",
    "\n",
    "samples_rgb = get_samples_rgb(sample_filename_list)\n",
    "samples_unwarp, samples_undist, samples_M, samples_Minv = get_samples_unwarp(samples_rgb, mtx, dist, src, dst)\n",
    "\n",
    "def updateHSVYellow(ch0_min, ch0_max, ch1_min, ch1_max, ch2_min, ch2_max):\n",
    "    \n",
    "    yellow_hsv_low  = np.array([ch0_min, ch1_min, ch2_min])\n",
    "    yellow_hsv_high = np.array([ch0_max, ch1_max, ch2_max])\n",
    "\n",
    "    images_to_plot = []\n",
    "    titles_to_plot = []\n",
    "    cmaps_to_plot = []\n",
    "    for idx in range(len(samples_unwarp)):\n",
    "        sample_unwarp = samples_unwarp[idx]\n",
    "        hsv = cv2.cvtColor(sample_unwarp, cv2.COLOR_RGB2HSV)\n",
    "        mask = color_mask(hsv, yellow_hsv_low, yellow_hsv_high)\n",
    "        image = np.copy(sample_unwarp)\n",
    "        out_img = cv2.bitwise_and(image, image, mask= mask)\n",
    "        images_to_plot.append(sample_unwarp)\n",
    "        images_to_plot.append(out_img)\n",
    "        titles_to_plot.append('unwarp')\n",
    "        titles_to_plot.append('h({},{}) s({},{}) v({},{})'.format(ch0_min, ch0_max, ch1_min, ch1_max, ch2_min, ch2_max))\n",
    "        cmaps_to_plot.append(None)\n",
    "        cmaps_to_plot.append(None)\n",
    "        \n",
    "    # plot and save image\n",
    "    out_file = \"hsv_yellow_masked.png\"\n",
    "    plot_images(rows=len(sample_filename_list), cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=cmaps_to_plot)\n",
    "\n",
    "interact(updateHSVYellow, \n",
    "         ch0_min=(0,255),\n",
    "         ch0_max=(0,255),\n",
    "         ch1_min=(0,255),\n",
    "         ch1_max=(0,255),\n",
    "         ch2_min=(0,255),\n",
    "         ch2_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 White color lane mask¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(unwarp, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def updateHSVWhite(ch0_min, ch0_max, ch1_min, ch1_max, ch2_min, ch2_max):\n",
    "    image = np.copy(unwarp)\n",
    "    white_hsv_low  = np.array([ch0_min, ch1_min, ch2_min])\n",
    "    white_hsv_high = np.array([ch0_max, ch1_max, ch2_max])\n",
    "    mask = color_mask(hsv, white_hsv_low, white_hsv_high)\n",
    "    out_img = cv2.bitwise_and(image, image, mask= mask)\n",
    "\n",
    "    # plot and save image\n",
    "    images_to_plot = [unwarp, out_img]\n",
    "    titles_to_plot = ['Unwarped', 'White mask H({},{}) S({},{}) V({},{})'.format(ch0_min, ch0_max, ch1_min, ch1_max, ch2_min, ch2_max)]\n",
    "    out_file = \"hsv_white_masked.png\"\n",
    "    plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,None])\n",
    "\n",
    "interact(updateHSVWhite, \n",
    "         ch0_min=(0,255),\n",
    "         ch0_max=(0,255),\n",
    "         ch1_min=(0,255),\n",
    "         ch1_max=(0,255),\n",
    "         ch2_min=(0,255),\n",
    "         ch2_max=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_lines_binary, yellow_mask = yellow_lines(unwarp)\n",
    "white_lines_binary, white_mask = white_lines(unwarp)\n",
    "lane_mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "\n",
    "# plot and save image\n",
    "images_to_plot = [yellow_lines_binary, white_lines_binary, lane_mask]\n",
    "titles_to_plot = ['yellow mask', 'white mask', 'yellow and white masks combined']\n",
    "out_file = \"yellow_white_mask.png\"\n",
    "plot_images(rows=1, cols=3, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,None,'gray'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SobelX and SobelY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def updateSobel(orient, kernel, thresh_min, thresh_max):\n",
    "    images_to_plot = []\n",
    "    titles_to_plot = []\n",
    "    cmaps_to_plot = []\n",
    "    for idx in range(len(samples_unwarp)):\n",
    "        sample_unwarp = samples_unwarp[idx]\n",
    "        sample_gray_filtered = apply_filter(sample_unwarp)\n",
    "        sample_gray_filtered_sobelx = abs_sobel_thresh(sample_gray_filtered, orient=orient, sobel_kernel=kernel, thresh=(thresh_min, thresh_max))\n",
    "        images_to_plot.append(sample_unwarp)\n",
    "        images_to_plot.append(sample_gray_filtered_sobelx)\n",
    "        titles_to_plot.append('unwarp')\n",
    "        titles_to_plot.append('sobel{} ({},{})'.format(orient, thresh_min, thresh_max))\n",
    "        cmaps_to_plot.append(None)\n",
    "        cmaps_to_plot.append('gray')\n",
    "        \n",
    "    # plot and save image\n",
    "    out_file = \"gradient_sobel{}.png\".format(orient)\n",
    "    plot_images(rows=len(sample_filename_list), cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=cmaps_to_plot)\n",
    "\n",
    "interact(updateSobel,\n",
    "         orient=['x', 'y'],\n",
    "         kernel=(1,31,2),\n",
    "         thresh_min=(0,255),\n",
    "         thresh_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 SobelMag Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def updateSobelMag(ksize, thresh_min, thresh_max):\n",
    "    \n",
    "    images_to_plot = []\n",
    "    titles_to_plot = []\n",
    "    cmaps_to_plot = []\n",
    "    for idx in range(len(samples_unwarp)):\n",
    "        sample_unwarp = samples_unwarp[idx]\n",
    "        out = mag_thresh(sample_unwarp, sobel_kernel=ksize, mag_thresh=(thresh_min, thresh_max))\n",
    "        images_to_plot.append(sample_unwarp)\n",
    "        images_to_plot.append(out)\n",
    "        titles_to_plot.append('unwarp')\n",
    "        titles_to_plot.append('SobelMag k({}), th({}, {})'.format(ksize, thresh_min, thresh_max))\n",
    "        cmaps_to_plot.append(None)\n",
    "        cmaps_to_plot.append('gray')\n",
    "    out_file = \"gradient_sobelMag.png\"\n",
    "    plot_images(rows=len(sample_filename_list), cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=cmaps_to_plot)\n",
    "\n",
    "interact(updateSobelMag, \n",
    "         ksize=(3,31,2),\n",
    "         thresh_min=(0,255),\n",
    "         thresh_max=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Sobel Direction Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def updateSobelDir(ksize, thresh_min, thresh_max):\n",
    "    out = dir_threshold(unwarp, sobel_kernel=ksize, thresh=(thresh_min, thresh_max))\n",
    "    images_to_plot = [unwarp, out]\n",
    "    titles_to_plot = ['Unwarped', 'SobelDir k({}), th({}, {})'.format(ksize, thresh_min, thresh_max)]\n",
    "    out_file = \"gradient_sobelDir.png\"\n",
    "    plot_images(rows=1, cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=[None,'gray'])\n",
    "\n",
    "interact(updateSobelDir, \n",
    "         ksize=(3,31,2),\n",
    "         thresh_min=(0.0,3.0),\n",
    "         thresh_max=(0.0,3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(image):\n",
    "    # chosen kernel size\n",
    "    ksize = 31 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "    # selected Gradient threshold\n",
    "    gradx = abs_sobel_thresh(apply_filter(image), orient='x', sobel_kernel=ksize, thresh=(50, 150))\n",
    "\n",
    "    # yellow and white lanes mask\n",
    "    yellow_lines_binary, yellow_mask = yellow_lines(image)\n",
    "    white_lines_binary, white_mask = white_lines(image)\n",
    "    lane_mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    lane_mask = lane_mask/255.0\n",
    "    \n",
    "    combined = np.zeros_like(gradx)\n",
    "    combined[((gradx == 1) | (lane_mask == 1))] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try against all test images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "# process and plot pipeline output for test images\n",
    "images_to_plot = []\n",
    "titles_to_plot = []\n",
    "cmaps_to_plot = []\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    undist = undistort_image(img, mtx, dist)\n",
    "    unwarp_test,M_test,Minv_test = unwarp_image(undist, src, dst)\n",
    "    \n",
    "    # process through pipeline\n",
    "    img_out = pipeline(unwarp_test)\n",
    "\n",
    "    images_to_plot.append(unwarp_test)\n",
    "    titles_to_plot.append(fname)\n",
    "    cmaps_to_plot.append(None)\n",
    "    images_to_plot.append(img_out)\n",
    "    titles_to_plot.append('pipeline output')\n",
    "    cmaps_to_plot.append('gray')\n",
    "out_file = \"test_pipeline.png\"\n",
    "plot_images(rows=len(images), cols=2, images_to_plot=images_to_plot, titles_to_plot=titles_to_plot, out_file=out_file, cmap=cmaps_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Locate the Lane Lines and Fit a Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ger outimage from pipeline\n",
    "img_out = pipeline(unwarp)\n",
    "\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "binary_warped = img_out\n",
    "\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_out, cmap='gray')\n",
    "plt.title('pipeline output')\n",
    "plt.subplot(122)\n",
    "plt.plot(histogram)\n",
    "plt.title('histogram')\n",
    "fig.savefig('./output/pipeline_histogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an output image to draw on and  visualize the result\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "print(\"Left base: {} Right base: {} Diff : {}\".format(leftx_base, rightx_base, (rightx_base - leftx_base)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sliding Window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "# windows\n",
    "nwindows = 9\n",
    "\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds, right_lane_inds, leftx_current, rightx_current = sliding_windows(\n",
    "    binary_warped, out_img, nonzerox, nonzeroy, leftx_current, rightx_current, margin, minpix, nwindows)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# update out image\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "#plot\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_out, cmap=\"gray\")\n",
    "plt.title(\"pipeline output\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(out_img)\n",
    "plt.title(\"Lane lines from sliding windows\")\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "fig.savefig('./output/sliding_window.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Left and Right Curvature (in pixels)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_eval = np.max(lefty)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "print(\"Left curvature : {:.2f} px  Right curvature : {:.2f} px\".format(left_curverad, right_curverad))\n",
    "# Example values: 1926.74 1908.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Left and Right Curvature (in meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit new polynomials to x,y in world space\n",
    "left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "# Calculate the new radii of curvature\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "# Now our radius of curvature is in meters\n",
    "print(\"Left curvature : {:.2f} m  Right curvature : {:.2f} m\".format(left_curverad, right_curverad))\n",
    "# Example values: 632.1 m    626.2 m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Distance of the car from the center of the lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_center = binary_warped.shape[1] / 2\n",
    "lane_center = (left_fit[-1] + right_fit[-1]) / 2\n",
    "diff = lane_center - img_center\n",
    "print(\"Distance from center : {:.2f} m\".format(diff * xm_per_pix))\n",
    "\n",
    "center_fit = (left_fit + right_fit) / 2\n",
    "center_curverad = ((1 + (2 * center_fit[0] * y_eval * ym_per_pix + center_fit[1])**2)**1.5) / np.absolute(2 * center_fit[0])\n",
    "print(\"Curvature : {:.2f} m \".format(center_curverad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Plot Selection Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get selection window/area\n",
    "result = add_selection_window(binary_warped, nonzerox, nonzeroy, left_lane_inds, right_lane_inds, left_fitx, right_fitx, ploty, margin)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "plt.title('identified lane with selection area')\n",
    "fig.savefig('./output/lane_selected_area.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warped = img_out\n",
    "\n",
    "# add overlay\n",
    "result, color_warp, newwarp = add_overlay(warped, undist_img, Minv, left_fitx, right_fitx, ploty)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(color_warp)\n",
    "plt.title(\"identified lane\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(newwarp)\n",
    "plt.title(\"lane warpPerspective\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(result)\n",
    "plt.title(\"overlay result\")\n",
    "fig.savefig('./output/overlay.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Alternate approach to Sliding Window for finding lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warped = img_out\n",
    "\n",
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "# If we found any window centers\n",
    "if len(window_centroids) > 0:\n",
    "\n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "\n",
    "    # Go through each level and draw the windows \t\n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channle \n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results \n",
    "\n",
    "# If no window centers found, just display orginal road image\n",
    "else:\n",
    "    output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "\n",
    "# Display the final results\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.imshow(output)\n",
    "plt.title('lane lines through centeroids approach')\n",
    "fig.savefig('./output/centeriod.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
